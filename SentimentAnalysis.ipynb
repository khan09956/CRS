{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyXAaTnmcQvg",
        "outputId": "914d0e2a-2c00-40c8-df78-161db0c65818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.33.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: requests in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khans\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NXdjnhf8ipgK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\khans\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# For data manipulation and analysis using DataFrames\n",
        "import pandas as pd\n",
        "# For splitting data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# For converting text data into numerical features (Bag of Words)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# For Naive Bayes classifier, a common choice for text classification\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# For various metrics used to evaluate the model's performance\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# For converting text data into TF-IDF (Term Frequency-Inverse Document Frequency) features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# For Support Vector Machine classifier, another option for text classification\n",
        "from sklearn.svm import SVC\n",
        "# For data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "# Enhanced data visualization based on matplotlib\n",
        "import seaborn as sns\n",
        "# For creating a sequential neural network model\n",
        "from keras.models import Sequential\n",
        "# For adding layers to the neural network\n",
        "from keras.layers import Dense\n",
        "# For regular expressions, used in text preprocessing\n",
        "import re\n",
        "# For working with PyTorch, a deep learning framework\n",
        "import torch\n",
        "# For loading and managing data for PyTorch models\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# For using pre-trained BERT model for sequence classification\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "# Natural Language Toolkit for text processing\n",
        "import nltk\n",
        "# List of common stopwords\n",
        "from nltk.corpus import stopwords\n",
        "# For lemmatizing words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# For tokenizing text into words\n",
        "from nltk.tokenize import word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfkgVW6-BZyj",
        "outputId": "e86babb7-3d22-4ea5-a6f7-df8090d0a8c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\khans\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\khans\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\khans\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Downloading the NLTK tokenizer models, necessary for word tokenization.\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Downloading the list of common stopwords from NLTK library.\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Downloading the WordNet lexical database, which is used for lemmatization.\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rOaGTe8Dj8eW"
      },
      "outputs": [],
      "source": [
        "# Read the TXT file\n",
        "with open(\"train.ft.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Split lines into labels and texts\n",
        "data = [line.strip().split(\" \", 1) for line in lines]\n",
        "\n",
        "# Separate labels and texts, handling the \"__label__\" prefix\n",
        "labels = [line[0].replace(\"__label__\", \"\") for line in data]\n",
        "texts = [line[1] for line in data]\n",
        "\n",
        "# Create a DataFrame\n",
        "df_train = pd.DataFrame({'label': labels, 'text': texts})\n",
        "\n",
        "# Save the DataFrame as CSV\n",
        "df_train.to_csv(\"train_dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VNyO7PLFkOQv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Read the TXT file\n",
        "with open(\"test.ft.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Split lines into labels and texts\n",
        "data = [line.strip().split(\" \", 1) for line in lines]\n",
        "\n",
        "# Separate labels and texts, handling the \"__label__\" prefix\n",
        "labels = [line[0].replace(\"__label__\", \"\") for line in data]\n",
        "texts = [line[1] for line in data]\n",
        "\n",
        "# Create a DataFrame\n",
        "df_test = pd.DataFrame({'label': labels, 'text': texts})\n",
        "\n",
        "# Save the DataFrame as CSV\n",
        "df_test.to_csv(\"test_dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uMHijaJDkP2R",
        "outputId": "b22cacb1-0e74-4562-fc81-1e9df6b5e268"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599995</th>\n",
              "      <td>1</td>\n",
              "      <td>Don't do it!!: The high chair looks great when...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599996</th>\n",
              "      <td>1</td>\n",
              "      <td>Looks nice, low functionality: I have used thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599997</th>\n",
              "      <td>1</td>\n",
              "      <td>compact, but hard to clean: We have a small ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599998</th>\n",
              "      <td>1</td>\n",
              "      <td>what is it saying?: not sure what this book is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599999</th>\n",
              "      <td>2</td>\n",
              "      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3600000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        label                                               text\n",
              "0           2  Stuning even for the non-gamer: This sound tra...\n",
              "1           2  The best soundtrack ever to anything.: I'm rea...\n",
              "2           2  Amazing!: This soundtrack is my favorite music...\n",
              "3           2  Excellent Soundtrack: I truly like this soundt...\n",
              "4           2  Remember, Pull Your Jaw Off The Floor After He...\n",
              "...       ...                                                ...\n",
              "3599995     1  Don't do it!!: The high chair looks great when...\n",
              "3599996     1  Looks nice, low functionality: I have used thi...\n",
              "3599997     1  compact, but hard to clean: We have a small ho...\n",
              "3599998     1  what is it saying?: not sure what this book is...\n",
              "3599999     2  Makes My Blood Run Red-White-And-Blue: I agree...\n",
              "\n",
              "[3600000 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mZY-2EwukkKL",
        "outputId": "8c32b4ea-d1aa-448b-f030-aa4b3afa724a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>One of the best game music soundtracks - for a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Batteries died within a year ...: I bought thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399995</th>\n",
              "      <td>1</td>\n",
              "      <td>Unbelievable- In a Bad Way: We bought this Tho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399996</th>\n",
              "      <td>1</td>\n",
              "      <td>Almost Great, Until it Broke...: My son reciev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399997</th>\n",
              "      <td>1</td>\n",
              "      <td>Disappointed !!!: I bought this toy for my son...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399998</th>\n",
              "      <td>2</td>\n",
              "      <td>Classic Jessica Mitford: This is a compilation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399999</th>\n",
              "      <td>1</td>\n",
              "      <td>Comedy Scene, and Not Heard: This DVD will be ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                               text\n",
              "0          2  Great CD: My lovely Pat has one of the GREAT v...\n",
              "1          2  One of the best game music soundtracks - for a...\n",
              "2          1  Batteries died within a year ...: I bought thi...\n",
              "3          2  works fine, but Maha Energy is better: Check o...\n",
              "4          2  Great for the non-audiophile: Reviewed quite a...\n",
              "...      ...                                                ...\n",
              "399995     1  Unbelievable- In a Bad Way: We bought this Tho...\n",
              "399996     1  Almost Great, Until it Broke...: My son reciev...\n",
              "399997     1  Disappointed !!!: I bought this toy for my son...\n",
              "399998     2  Classic Jessica Mitford: This is a compilation...\n",
              "399999     1  Comedy Scene, and Not Heard: This DVD will be ...\n",
              "\n",
              "[400000 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hurRC3hbzbDE",
        "outputId": "25286cf3-19eb-4378-d97d-84eadb8f9930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.84      0.85      0.84      9962\n",
            "           2       0.85      0.84      0.84     10038\n",
            "\n",
            "    accuracy                           0.84     20000\n",
            "   macro avg       0.84      0.84      0.84     20000\n",
            "weighted avg       0.84      0.84      0.84     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the training dataset\n",
        "train_df = pd.read_csv(\"train_dataset.csv\")\n",
        "\n",
        "# Load the testing dataset\n",
        "test_df = pd.read_csv(\"test_dataset.csv\")\n",
        "\n",
        "# Use around 20000 samples from the training and testing datasets\n",
        "train_samples = 20000\n",
        "test_samples = 20000\n",
        "\n",
        "# Limit the number of samples\n",
        "train_df = train_df.sample(train_samples, random_state=42,replace='True')\n",
        "test_df = test_df.sample(test_samples, random_state=42,replace='True')\n",
        "\n",
        "# Preprocessing: Clean and tokenize text\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Tokenize\n",
        "    tokens = text.split()\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)\n",
        "test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)\n",
        "\n",
        "# Preprocessing: TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['cleaned_text'])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df['cleaned_text'])\n",
        "\n",
        "# Convert labels to integers\n",
        "y_train = train_df['label'].astype(int)\n",
        "y_test = test_df['label'].astype(int)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate classification report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVD3HLcLsC-Q",
        "outputId": "3259dcec-ea63-4d8b-80bf-6faf69604493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "45000/45000 [==============================] - 46014s 1s/step - loss: -723.8774 - accuracy: 0.4989 - val_loss: -1432.4791 - val_accuracy: 0.5042\n",
            "Epoch 2/5\n",
            "45000/45000 [==============================] - 10590s 235ms/step - loss: -2174.9834 - accuracy: 0.4989 - val_loss: -2871.2207 - val_accuracy: 0.5042\n",
            "Epoch 3/5\n",
            "45000/45000 [==============================] - 9837s 219ms/step - loss: -3629.2388 - accuracy: 0.4989 - val_loss: -4310.3018 - val_accuracy: 0.5042\n",
            "Epoch 4/5\n",
            "45000/45000 [==============================] - 9796s 218ms/step - loss: -5083.4683 - accuracy: 0.4989 - val_loss: -5748.9883 - val_accuracy: 0.5042\n",
            "Epoch 5/5\n",
            "45000/45000 [==============================] - 16115s 358ms/step - loss: -6537.3442 - accuracy: 0.4989 - val_loss: -7187.7769 - val_accuracy: 0.5042\n",
            "12500/12500 [==============================] - 356s 28ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\khans\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\khans\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\khans\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      1.00      0.67    200000\n",
            "           2       0.00      0.00      0.00    200000\n",
            "\n",
            "    accuracy                           0.50    400000\n",
            "   macro avg       0.25      0.50      0.33    400000\n",
            "weighted avg       0.25      0.50      0.33    400000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[200000      0]\n",
            " [200000      0]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train_dataset.csv\")\n",
        "test_df = pd.read_csv(\"test_dataset.csv\")\n",
        "\n",
        "# Advanced preprocessing: Tokenization and padding\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_df['text'])\n",
        "X_train_tokens = tokenizer.texts_to_sequences(train_df['text'])\n",
        "X_test_tokens = tokenizer.texts_to_sequences(test_df['text'])\n",
        "\n",
        "max_sequence_length = max(max(len(sequence) for sequence in X_train_tokens),\n",
        "                          max(len(sequence) for sequence in X_test_tokens))\n",
        "X_train_padded = pad_sequences(X_train_tokens, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_tokens, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "# Convert labels to numpy arrays\n",
        "y_train = np.array(train_df['label'])\n",
        "y_test = np.array(test_df['label'])\n",
        "\n",
        "# Build the ANN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_sequence_length))\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_padded, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_prob = model.predict(X_test_padded)\n",
        "y_pred = np.round(y_pred_prob).astype(int)\n",
        "\n",
        "# Calculate classification report and confusion matrix\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBZnmDyFfW_1",
        "outputId": "2b3049bd-5f42-4a12-aefc-1579015fb333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.86      0.86      9962\n",
            "           2       0.86      0.86      0.86     10038\n",
            "\n",
            "    accuracy                           0.86     20000\n",
            "   macro avg       0.86      0.86      0.86     20000\n",
            "weighted avg       0.86      0.86      0.86     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the training dataset\n",
        "train_df = pd.read_csv(\"train_dataset.csv\")\n",
        "\n",
        "# Load the testing dataset\n",
        "test_df = pd.read_csv(\"test_dataset.csv\")\n",
        "\n",
        "# Use around 20000 samples from the training and testing datasets\n",
        "train_samples = 20000\n",
        "test_samples = 20000\n",
        "\n",
        "# Limit the number of samples\n",
        "train_df = train_df.sample(train_samples, random_state=42,replace='True')\n",
        "test_df = test_df.sample(test_samples, random_state=42,replace='True')\n",
        "\n",
        "# Preprocessing: Clean text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)\n",
        "test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)\n",
        "\n",
        "# Preprocessing: Tokenization, stopwords removal, and lemmatization\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text_advanced(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "train_df['processed_text'] = train_df['cleaned_text'].apply(preprocess_text_advanced)\n",
        "test_df['processed_text'] = test_df['cleaned_text'].apply(preprocess_text_advanced)\n",
        "\n",
        "# Preprocessing: TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['processed_text'])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df['processed_text'])\n",
        "\n",
        "# Convert labels to integers\n",
        "y_train = train_df['label'].astype(int)\n",
        "y_test = test_df['label'].astype(int)\n",
        "\n",
        "# Train an SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = svm_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate classification report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuXUPhb7dQcu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
